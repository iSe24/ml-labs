# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b6RslcBmbv4ljfXH-wH2kddUdmFAA_w9
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline 
sns.set(style="ticks")

data = pd.read_csv('dc-wikia-data.csv', sep=",")
data.head()

data.isnull().sum()

data.dtypes

"""1. Обработка пропусков в данных
1.1. Простые стратегии - удаление или заполнение нулями
"""

data_new_1 = data.dropna(axis=1, how='any')
(data.shape, data_new_1.shape)

data_new_2 = data.dropna(axis=0, how='any')
(data.shape, data_new_2.shape)

data_new_3 = data.fillna(0)
data_new_3.head()

"""1.2. "Внедрение значений" - импьютация (imputation)
1.2.1. Обработка пропусков в числовых данных
"""

# Выберем числовые колонки с пропущенными значениями
# Цикл по колонкам датасета
num_cols = []
for col in data.columns:
    # Количество пустых значений 
    temp_null_count = data[data[col].isnull()].shape[0]
    dt = str(data[col].dtype)
    if temp_null_count>0 and (dt=='float64' or dt=='int64'):
        num_cols.append(col)        
        print('Колонка {}. Тип данных {}. Количество пустых значений {}.'.format(col, dt, temp_null_count))

# Фильтр по пустым значениям поля MasVnrArea 
data[data['YEAR'].isnull()]
# Сохраняем индексы
flt_index = data[data['YEAR'].isnull()].index
flt_index

for rows in flt_index:
  data.YEAR[rows]=data.YEAR.median()

# Фильтр по пустым значениям поля MasVnrArea 
data[data['YEAR'].isnull()]
# Сохраняем индексы
flt_index = data[data['YEAR'].isnull()].index
flt_index

data[data['APPEARANCES'].isnull()]
# Сохраняем индексы
flt_index = data[data['APPEARANCES'].isnull()].index
flt_index

data.APPEARANCES = data.APPEARANCES.mean()

"""1.2.2. Обработка пропусков в категориальных данных"""

# Выберем категориальные колонки с пропущенными значениями
# Цикл по колонкам датасета
cat_cols = []
for col in data.columns:
    # Количество пустых значений 
    temp_null_count = data[data[col].isnull()].shape[0]
    dt = str(data[col].dtype)
    if temp_null_count>0 and (dt=='object'):
        cat_cols.append(col)
        temp_perc = round((temp_null_count / data.shape[0]) * 100.0, 2)
        print('Колонка {}. Тип данных {}. Количество пустых значений {}, {}%.'.format(col, dt, temp_null_count,temp_perc))

MaxPassEmbarked = data.groupby('ALIVE').count()['page_id']
data.ALIVE[data.ALIVE.isnull()] = MaxPassEmbarked[MaxPassEmbarked == MaxPassEmbarked.max()].index[0]

data[data[col].isnull()].shape[0]

"""2. Преобразование категориальных признаков в числовые"""

data.ALIGN.replace({'Good Characters':'1','Bad Characters':'0'},inplace=True)
data.head()

from sklearn.preprocessing import LabelEncoder
label = LabelEncoder()
dicts = {}

data.ALIGN = label.fit_transform(data.ALIGN.astype(str))
label.fit(data.ALIGN.drop_duplicates()) #задаем список значений для кодирования

dicts['ALIGN'] = list(label.classes_)
data.ALIGN = label.transform(data.ALIGN) #заменяем значения из списка кодами закодированных элементов 
flt_index = data['ALIGN'].unique()
flt_index

import pandas 
cat_columns = ['ID']
data_processed = pandas.get_dummies(data, prefix_sep="__",
                              columns=cat_columns)
data_processed

"""3. Масштабирование данных
Термины "масштабирование" и "нормализация" часто используются как синонимы. Масштабирование предполагает изменение диапазона измерения величины, а нормализация - изменение распределения этой величины.

1. MinMax масштабирование
"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer

sc1 = MinMaxScaler()
sc1_data = sc1.fit_transform(data[['YEAR']])
plt.hist(data['YEAR'], 50)
plt.show()

"""3.2. Масштабирование данных на основе Z-оценки - StandardScaler¶"""

sc2 = StandardScaler()
sc2_data = sc2.fit_transform(data[['YEAR']])

plt.hist(sc2_data, 50)
plt.show()

sc3 = Normalizer()
sc3_data = sc3.fit_transform(data[['YEAR']])
flt_index = data['YEAR'].unique()
flt_index
plt.hist(sc3_data, 50)
plt.show()